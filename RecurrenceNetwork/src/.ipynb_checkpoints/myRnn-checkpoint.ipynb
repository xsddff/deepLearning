{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0a6fbe-fa72-4ead-a47d-ea78a1a25101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from turtle import color\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from seq import seqDataLoader\n",
    "from voc import Vocab,read_dataset,tokenize\n",
    "from model import RnnModelScratch\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267aa453-b7da-4bc2-b259-a05f41c9b20b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_vocabulary(file):\n",
    "    # 加载数据集 和 词表\n",
    "    lines = read_dataset(file)\n",
    "    tokens = tokenize(lines)\n",
    "    corpus = [tk for token in tokens for tk in token]\n",
    "    voc = Vocab(corpus)\n",
    "    return voc,corpus\n",
    "\n",
    "def train(net,corpus,epoches,device='cpu',lr=1):\n",
    "\n",
    "  dataLoader = seqDataLoader(corpus,batch_size=16,num_steps=5,is_random=True)\n",
    "\n",
    "  loss = nn.CrossEntropyLoss()\n",
    "  if isinstance(net,nn.Module):\n",
    "    opt = torch.optim.SGD(net.parameters(),lr=lr)\n",
    "  else:\n",
    "    opt = torch.optim.SGD(net.params,lr=lr)\n",
    "  state = None\n",
    "\n",
    "  total_losses = []\n",
    "  with tqdm(total = epoches,desc='模型训练中') as pbar:\n",
    "    for epoch in range(epoches):\n",
    "      losses = train_epoch(net,state,dataLoader,loss,opt,is_random=True,device=device)\n",
    "      total_losses.append(losses)\n",
    "      if (epoch+1) % 1 == 0:\n",
    "        pbar.update(1)\n",
    "        \n",
    "  return total_losses\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(model,state,train_iter,loss,opt,is_random=False,device='cpu'):\n",
    "  losses = 0\n",
    "  total = 0\n",
    "  for X,Y in train_iter:   # 有个 batches 数量的 序列，并且序列式拥有顺序的\n",
    "    if state is None or is_random:\n",
    "      state = model.begin_state(X.shape[0],device)\n",
    "    else:\n",
    "      for s in state:   \n",
    "        s.detach_()     # 对每个batch执行时间步截断\n",
    "  \n",
    "    X = X.to(device)\n",
    "    y_pre,state = model(X,state)\n",
    "    y = F.one_hot(Y.T.reshape(-1),num_classes=y_pre.shape[-1]).float().to(device)\n",
    "    l = loss(y_pre,y).mean()\n",
    "    opt.zero_grad()\n",
    "    l.backward()\n",
    "    clip_grad(model,1)\n",
    "    opt.step()\n",
    "    losses += l.item() * X.size(0)\n",
    "    total += X.size(0)\n",
    "  return losses/total\n",
    "\n",
    "\n",
    "def clip_grad(model,theta):\n",
    "  if isinstance(model,nn.Module):\n",
    "    params = [p for p in model.parameters() if p.requires_grad]   # model.parameters()  返回的是参数迭代对象，每个迭代对象是各层网络的参数矩阵\n",
    "  else:\n",
    "    params: list = model.params\n",
    "\n",
    "  tmp = sum(torch.sum(p ** 2) for p in params)\n",
    "  norm = torch.sqrt(tmp)\n",
    "\n",
    "  if norm > theta:\n",
    "    for p in params:\n",
    "      p.grad = p.grad * theta / norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cbbcaa-056d-44d7-9dbc-aa9c0286ba17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "voc,corpus = create_vocabulary('../dataset/time_machine.txt')\n",
    "corpus = voc[corpus]\n",
    "# 加载模型\n",
    "net = RnnModelScratch(voc_size=len(voc),num_hiddens=256,device=device)\n",
    "total_losses = train(net,corpus,100,device,lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b854dfb-df77-4759-98fb-2c1a9d9201c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(range(len(total_losses)),total_losses,color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c4e930-0d41-4486-8214-7e94b5f569f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(corpus,prex_nums,model,device):\n",
    "    outputs = [ corpus[0] ]\n",
    "    def get_data():\n",
    "        return torch.tensor(outputs[-1]).reshape(1,1).to(device)\n",
    "    H = model.begin_state(1,device)\n",
    "    for i in corpus[1:]:\n",
    "        _,H = model(get_data(),H)\n",
    "        outputs.append(i)\n",
    "    for i in range(prex_nums):\n",
    "        y,H = model(get_data(),H)\n",
    "        y = torch.argmax(y,dim=-1).item()\n",
    "        outputs.append(y)\n",
    "    return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134365ed-3485-4217-9afd-72c1464297b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    str = 'time traveller '\n",
    "    str = str.split()\n",
    "    corpus = voc[str]\n",
    "    print(corpus)\n",
    "    predict_str = predict(corpus,10,net,device)\n",
    "    print(predict_str)\n",
    "    predict_str = voc(predict_str)\n",
    "    print(predict_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb629614-73a6-421b-82da-9c8ab8739622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
