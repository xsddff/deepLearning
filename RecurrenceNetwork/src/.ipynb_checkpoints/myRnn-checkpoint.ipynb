{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0a6fbe-fa72-4ead-a47d-ea78a1a25101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from turtle import color\n",
    "from sympy import true\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from data import seqDataLoader\n",
    "from data import Vocab,read_dataset,tokenize\n",
    "from models import RnnModelScratch\n",
    "from models import GRUModelScratch\n",
    "from models import lstmModelScratch\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "267aa453-b7da-4bc2-b259-a05f41c9b20b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_vocabulary(file):\n",
    "    # 加载数据集 和 词表\n",
    "    lines = read_dataset(file)\n",
    "    tokens = tokenize(lines)\n",
    "    corpus = [tk for token in tokens for tk in token]\n",
    "    voc = Vocab(corpus)\n",
    "    return voc,corpus\n",
    "\n",
    "def train(net,corpus,epoches,device='cpu',lr=1.2):\n",
    "\n",
    "  dataLoader = seqDataLoader(corpus,batch_size=16,num_steps=5,is_random=False)\n",
    "\n",
    "  loss = nn.CrossEntropyLoss()\n",
    "  if isinstance(net,nn.Module):\n",
    "    opt = torch.optim.SGD(net.parameters(),lr=lr)\n",
    "  else:\n",
    "    opt = torch.optim.SGD(net.params,lr=lr)\n",
    "\n",
    "  consine_scheduler = CosineAnnealingLR( opt,T_max=80,eta_min=0.1 )\n",
    "  scheduler = GradualWarmupScheduler(opt,2,20,consine_scheduler)\n",
    "\n",
    "  state = None\n",
    "\n",
    "  total_losses = []\n",
    "  with tqdm(total = epoches,desc='模型训练中') as pbar:\n",
    "    for epoch in range(epoches):\n",
    "      losses = train_epoch(net,state,dataLoader,loss,opt,device=device,is_random=True)\n",
    "      total_losses.append(losses)\n",
    "      if (epoch+1) % 1 == 0:\n",
    "        pbar.update(1)\n",
    "      scheduler.step()\n",
    "        \n",
    "  return total_losses\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(model,state,train_iter,loss,opt,is_random=False,device='cpu'):\n",
    "  losses = 0\n",
    "  total = 0\n",
    "  for X,Y in train_iter:   # 有个 batches 数量的 序列，并且序列式拥有顺序的\n",
    "    if state is None or is_random:\n",
    "      state = model.begin_state(X.shape[0],device)\n",
    "    else:\n",
    "      if isinstance(state,tuple):\n",
    "        for s in state:\n",
    "          s.detach_()\n",
    "      else:\n",
    "        state.detach_()     # 对每个batch执行时间步截断\n",
    "  \n",
    "    X = X.to(device)\n",
    "    y_pre,state = model(X,state)\n",
    "    # y = F.one_hot(Y.T.reshape(-1),num_classes=y_pre.shape[-1]).float().to(device)\n",
    "    y = Y.T.reshape(-1).to(device)\n",
    "    l = loss(y_pre,y).mean()\n",
    "    opt.zero_grad()\n",
    "    l.backward()\n",
    "    clip_grad(model,1)   # 计算梯度并梯度裁切\n",
    "    opt.step()\n",
    "    losses += l.item() * X.size(0)\n",
    "    total += X.size(0)\n",
    "  return losses/total\n",
    "\n",
    "\n",
    "def clip_grad(model,theta):\n",
    "  if isinstance(model,nn.Module):\n",
    "    params = [p for p in model.parameters() if p.requires_grad]   # model.parameters()  返回的是参数迭代对象，每个迭代对象是各层网络的参数矩阵\n",
    "  else:\n",
    "    params: list = model.params\n",
    "\n",
    "  tmp = sum(torch.sum(p ** 2) for p in params)\n",
    "  norm = torch.sqrt(tmp)\n",
    "\n",
    "  if norm > theta:\n",
    "    for p in params:\n",
    "      if p.grad is not None:\n",
    "        p.grad = p.grad * theta / norm\n",
    "  \n",
    "  # torch.nn.utils.clip_grad.clip_grad_norm_(model.parameters(),theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20cbbcaa-056d-44d7-9dbc-aa9c0286ba17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "voc,corpus = create_vocabulary('../dataset/time_machine.txt')\n",
    "corpus = voc[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7750b6d3-1419-4c82-8cde-1f3235ec5d47",
   "metadata": {},
   "source": [
    "# 自定义神经网络模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67943ecd-3460-442c-97a8-b7df811448b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中:   1%|▌                                                           | 1/100 [00:04<07:27,  4.52s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 加载模型\u001b[39;00m\n\u001b[1;32m      2\u001b[0m net_rnn \u001b[38;5;241m=\u001b[39m RnnModelScratch(voc_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(voc),num_hiddens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,device\u001b[38;5;241m=\u001b[39mdevice,num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m total_losses_rnn \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_rnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, corpus, epoches, device, lr)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total \u001b[38;5;241m=\u001b[39m epoches,desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m模型训练中\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m     26\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoches):\n\u001b[0;32m---> 27\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mis_random\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     total_losses\u001b[38;5;241m.\u001b[39mappend(losses)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[11], line 51\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, state, train_iter, loss, opt, is_random, device)\u001b[0m\n\u001b[1;32m     48\u001b[0m     state\u001b[38;5;241m.\u001b[39mdetach_()     \u001b[38;5;66;03m# 对每个batch执行时间步截断\u001b[39;00m\n\u001b[1;32m     50\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 51\u001b[0m y_pre,state \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# y = F.one_hot(Y.T.reshape(-1),num_classes=y_pre.shape[-1]).float().to(device)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m y \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/xuan/deepLearning/RecurrenceNetwork/src/models/model.py:81\u001b[0m, in \u001b[0;36mRnnModelScratch.__call__\u001b[0;34m(self, X, H)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03mX: (batch_size,seq_len)\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     80\u001b[0m X \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mone_hot(X\u001b[38;5;241m.\u001b[39mT,num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoc_size)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/xuan/deepLearning/RecurrenceNetwork/src/models/model.py:58\u001b[0m, in \u001b[0;36mmy_nn.rnn.<locals>.forward\u001b[0;34m(inputs, h)\u001b[0m\n\u001b[1;32m     56\u001b[0m new_h \u001b[38;5;241m=\u001b[39m [ pre_layer_h ]     \u001b[38;5;66;03m# 这里不用h[i]重复复制，否则会导致梯度计算版本不一致\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):  \n\u001b[0;32m---> 58\u001b[0m   layer_h \u001b[38;5;241m=\u001b[39m pre_layer_h \u001b[38;5;241m@\u001b[39m \u001b[43mW_xh\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m h[i] \u001b[38;5;241m@\u001b[39m W_hh[i] \u001b[38;5;241m+\u001b[39m b_h[i]\n\u001b[1;32m     59\u001b[0m   new_h\u001b[38;5;241m.\u001b[39mappend(layer_h)\n\u001b[1;32m     60\u001b[0m h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(new_h,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "net_rnn = RnnModelScratch(voc_size=len(voc),num_hiddens=256,device=device,num_layers=3)\n",
    "total_losses_rnn = train(net_rnn,corpus,100,device,lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c163caf1-a0b0-4d14-886e-e75bd3a4f03c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中: 100%|██████████████████████████████████████████████████████████| 100/100 [05:04<00:00,  3.04s/it]\n"
     ]
    }
   ],
   "source": [
    "net_gru = GRUModelScratch(voc_size=len(voc),num_hiddens=256,device=device)\n",
    "total_losses_gru = train(net_gru,corpus,100,device,lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a22c8b21-99a9-42a6-be18-eac21cade180",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中: 100%|██████████████████████████████████████████████████████████| 300/300 [17:41<00:00,  3.54s/it]\n"
     ]
    }
   ],
   "source": [
    "net_lstm = lstmModelScratch(voc_size=len(voc),num_hiddens=256,device=device)\n",
    "total_losses_lstm = train(net_lstm,corpus,300,device,lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b854dfb-df77-4759-98fb-2c1a9d9201c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'total_losses_gru' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(total_losses_rnn)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(total_losses_rnn)),total_losses_rnn,color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrnn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mtotal_losses_gru\u001b[49m)),total_losses_gru,color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgru\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(total_losses_lstm)),total_losses_lstm,color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'total_losses_gru' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGdCAYAAADuR1K7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAf20lEQVR4nO3de3BU9f3/8deGkATFTcotayARbalEpNAGE8J0htbsGJSOpOKIGQSkGSkV0BpKAUUy2nbSilZQUMaZOgxVCoVaWpHi0GCVysoleOEWxnaUq5uAmA2iJDH5/P7wx9qVEMFvTpJ983zMnGE4+zm7n8+ZwD7ncHbxOeecAAAAjEjo6AkAAAC0JeIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAApiR29AQ6QnNzs44eParLLrtMPp+vo6cDAADOg3NOJ0+eVEZGhhISzn195qKMm6NHjyozM7OjpwEAAL6GQ4cOqV+/fud8/KKMm8suu0zS5yfH7/d38GwAAMD5qKurU2ZmZvR9/Fwuyrg5809Rfr+fuAEAIM581S0l3FAMAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADClXeJmyZIl6t+/v1JSUpSXl6dt27a1On716tUaOHCgUlJSNHjwYK1fv/6cY6dOnSqfz6eFCxe28awBAEA88jxuVq1apdLSUpWVlWnnzp0aMmSICgsLVVNT0+L4LVu2qLi4WCUlJXrzzTdVVFSkoqIi7d69+6yxf/3rX/XGG28oIyPD62UAAIA44Xnc/P73v9ddd92lyZMn65prrtHSpUt1ySWX6Nlnn21x/KJFizRq1CjNmjVL2dnZ+tWvfqXvfe97Wrx4ccy4I0eOaMaMGXr++efVtWtXr5cBAADihKdx09DQoMrKSgWDwS9eMCFBwWBQoVCoxWNCoVDMeEkqLCyMGd/c3KwJEyZo1qxZGjRo0FfOo76+XnV1dTEbAACwydO4OX78uJqampSenh6zPz09XeFwuMVjwuHwV47/3e9+p8TERN1zzz3nNY/y8nKlpqZGt8zMzAtcCQAAiBdx92mpyspKLVq0SMuWLZPP5zuvY+bOnatIJBLdDh065PEsAQBAR/E0bnr16qUuXbqouro6Zn91dbUCgUCLxwQCgVbHb968WTU1NcrKylJiYqISExN14MABzZw5U/3792/xOZOTk+X3+2M2AABgk6dxk5SUpJycHFVUVET3NTc3q6KiQvn5+S0ek5+fHzNekjZu3BgdP2HCBL3zzjt66623oltGRoZmzZqll19+2bvFAACAuJDo9QuUlpZq0qRJGjZsmHJzc7Vw4UKdOnVKkydPliRNnDhRffv2VXl5uSTp3nvv1ciRI/XYY49p9OjRWrlypXbs2KFnnnlGktSzZ0/17Nkz5jW6du2qQCCgq6++2uvlAACATs7zuBk3bpyOHTum+fPnKxwOa+jQodqwYUP0puGDBw8qIeGLC0gjRozQihUrNG/ePN1///0aMGCA1q5dq2uvvdbrqQIAAAN8zjnX0ZNob3V1dUpNTVUkEuH+GwAA4sT5vn/H3aelAAAAWkPcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwJR2iZslS5aof//+SklJUV5enrZt29bq+NWrV2vgwIFKSUnR4MGDtX79+uhjjY2Nmj17tgYPHqxLL71UGRkZmjhxoo4ePer1MgAAQBzwPG5WrVql0tJSlZWVaefOnRoyZIgKCwtVU1PT4vgtW7aouLhYJSUlevPNN1VUVKSioiLt3r1bkvTJJ59o586devDBB7Vz50698MIL2r9/v26++WavlwIAAOKAzznnvHyBvLw8XXfddVq8eLEkqbm5WZmZmZoxY4bmzJlz1vhx48bp1KlTWrduXXTf8OHDNXToUC1durTF19i+fbtyc3N14MABZWVlfeWc6urqlJqaqkgkIr/f/zVXBgAA2tP5vn97euWmoaFBlZWVCgaDX7xgQoKCwaBCoVCLx4RCoZjxklRYWHjO8ZIUiUTk8/mUlpbW4uP19fWqq6uL2QAAgE2exs3x48fV1NSk9PT0mP3p6ekKh8MtHhMOhy9o/OnTpzV79mwVFxefs+LKy8uVmpoa3TIzM7/GagAAQDyI609LNTY26rbbbpNzTk8//fQ5x82dO1eRSCS6HTp0qB1nCQAA2lOil0/eq1cvdenSRdXV1TH7q6urFQgEWjwmEAic1/gzYXPgwAFt2rSp1X97S05OVnJy8tdcBQAAiCeeXrlJSkpSTk6OKioqovuam5tVUVGh/Pz8Fo/Jz8+PGS9JGzdujBl/Jmzeffdd/fOf/1TPnj29WQAAAIg7nl65kaTS0lJNmjRJw4YNU25urhYuXKhTp05p8uTJkqSJEyeqb9++Ki8vlyTde++9GjlypB577DGNHj1aK1eu1I4dO/TMM89I+jxsbr31Vu3cuVPr1q1TU1NT9H6cHj16KCkpyeslAQCATszzuBk3bpyOHTum+fPnKxwOa+jQodqwYUP0puGDBw8qIeGLC0gjRozQihUrNG/ePN1///0aMGCA1q5dq2uvvVaSdOTIEf3973+XJA0dOjTmtV555RX94Ac/8HpJAACgE/P8e246I77nBgCA+NMpvucGAACgvRE3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMKVd4mbJkiXq37+/UlJSlJeXp23btrU6fvXq1Ro4cKBSUlI0ePBgrV+/PuZx55zmz5+vyy+/XN26dVMwGNS7777r5RIAAECc8DxuVq1apdLSUpWVlWnnzp0aMmSICgsLVVNT0+L4LVu2qLi4WCUlJXrzzTdVVFSkoqIi7d69OzrmkUce0RNPPKGlS5dq69atuvTSS1VYWKjTp097vRwAANDJ+ZxzzssXyMvL03XXXafFixdLkpqbm5WZmakZM2Zozpw5Z40fN26cTp06pXXr1kX3DR8+XEOHDtXSpUvlnFNGRoZmzpypX/ziF5KkSCSi9PR0LVu2TLfffvtXzqmurk6pqamKRCLy+/1ttFIAAOCl833/9vTKTUNDgyorKxUMBr94wYQEBYNBhUKhFo8JhUIx4yWpsLAwOv69995TOByOGZOamqq8vLxzPmd9fb3q6upiNgAAYJOncXP8+HE1NTUpPT09Zn96errC4XCLx4TD4VbHn/n1Qp6zvLxcqamp0S0zM/NrrQcAAHR+F8WnpebOnatIJBLdDh061NFTAgAAHvE0bnr16qUuXbqouro6Zn91dbUCgUCLxwQCgVbHn/n1Qp4zOTlZfr8/ZgMAADZ5GjdJSUnKyclRRUVFdF9zc7MqKiqUn5/f4jH5+fkx4yVp48aN0fFXXnmlAoFAzJi6ujpt3br1nM8JAAAuHolev0BpaakmTZqkYcOGKTc3VwsXLtSpU6c0efJkSdLEiRPVt29flZeXS5LuvfdejRw5Uo899phGjx6tlStXaseOHXrmmWckST6fTz//+c/161//WgMGDNCVV16pBx98UBkZGSoqKvJ6OQAAoJPzPG7GjRunY8eOaf78+QqHwxo6dKg2bNgQvSH44MGDSkj44gLSiBEjtGLFCs2bN0/333+/BgwYoLVr1+raa6+NjvnlL3+pU6dOacqUKaqtrdX3v/99bdiwQSkpKV4vBwAAdHKef89NZ8T33AAAEH86xffcAAAAtDfiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKZ4FjcnTpzQ+PHj5ff7lZaWppKSEn388cetHnP69GlNmzZNPXv2VPfu3TV27FhVV1dHH3/77bdVXFyszMxMdevWTdnZ2Vq0aJFXSwAAAHHIs7gZP3689uzZo40bN2rdunV67bXXNGXKlFaPue+++/Tiiy9q9erVevXVV3X06FHdcsst0ccrKyvVp08fPffcc9qzZ48eeOABzZ07V4sXL/ZqGQAAIM74nHOurZ903759uuaaa7R9+3YNGzZMkrRhwwbddNNNOnz4sDIyMs46JhKJqHfv3lqxYoVuvfVWSVJVVZWys7MVCoU0fPjwFl9r2rRp2rdvnzZt2nTe86urq1NqaqoikYj8fv/XWCEAAGhv5/v+7cmVm1AopLS0tGjYSFIwGFRCQoK2bt3a4jGVlZVqbGxUMBiM7hs4cKCysrIUCoXO+VqRSEQ9evRou8kDAIC4lujFk4bDYfXp0yf2hRIT1aNHD4XD4XMek5SUpLS0tJj96enp5zxmy5YtWrVqlV566aVW51NfX6/6+vro7+vq6s5jFQAAIB5d0JWbOXPmyOfztbpVVVV5NdcYu3fv1pgxY1RWVqYbbrih1bHl5eVKTU2NbpmZme0yRwAA0P4u6MrNzJkzdeedd7Y65qqrrlIgEFBNTU3M/s8++0wnTpxQIBBo8bhAIKCGhgbV1tbGXL2prq4+65i9e/eqoKBAU6ZM0bx5875y3nPnzlVpaWn093V1dQQOAABGXVDc9O7dW7179/7Kcfn5+aqtrVVlZaVycnIkSZs2bVJzc7Py8vJaPCYnJ0ddu3ZVRUWFxo4dK0nav3+/Dh48qPz8/Oi4PXv26Prrr9ekSZP0m9/85rzmnZycrOTk5PMaCwAA4psnn5aSpBtvvFHV1dVaunSpGhsbNXnyZA0bNkwrVqyQJB05ckQFBQVavny5cnNzJUk/+9nPtH79ei1btkx+v18zZsyQ9Pm9NdLn/xR1/fXXq7CwUAsWLIi+VpcuXc4rus7g01IAAMSf833/9uSGYkl6/vnnNX36dBUUFCghIUFjx47VE088EX28sbFR+/fv1yeffBLd9/jjj0fH1tfXq7CwUE899VT08TVr1ujYsWN67rnn9Nxzz0X3X3HFFXr//fe9WgoAAIgjnl256cy4cgMAQPzp0O+5AQAA6CjEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCmexc2JEyc0fvx4+f1+paWlqaSkRB9//HGrx5w+fVrTpk1Tz5491b17d40dO1bV1dUtjv3www/Vr18/+Xw+1dbWerACAAAQjzyLm/Hjx2vPnj3auHGj1q1bp9dee01Tpkxp9Zj77rtPL774olavXq1XX31VR48e1S233NLi2JKSEn3nO9/xYuoAACCO+Zxzrq2fdN++fbrmmmu0fft2DRs2TJK0YcMG3XTTTTp8+LAyMjLOOiYSiah3795asWKFbr31VklSVVWVsrOzFQqFNHz48OjYp59+WqtWrdL8+fNVUFCgjz76SGlpaec9v7q6OqWmpioSicjv9//fFgsAANrF+b5/e3LlJhQKKS0tLRo2khQMBpWQkKCtW7e2eExlZaUaGxsVDAaj+wYOHKisrCyFQqHovr179+rhhx/W8uXLlZBwftOvr69XXV1dzAYAAGzyJG7C4bD69OkTsy8xMVE9evRQOBw+5zFJSUlnXYFJT0+PHlNfX6/i4mItWLBAWVlZ5z2f8vJypaamRrfMzMwLWxAAAIgbFxQ3c+bMkc/na3Wrqqryaq6aO3eusrOzdccdd1zwcZFIJLodOnTIoxkCAICOlnghg2fOnKk777yz1TFXXXWVAoGAampqYvZ/9tlnOnHihAKBQIvHBQIBNTQ0qLa2NubqTXV1dfSYTZs2adeuXVqzZo0k6cztQr169dIDDzyghx56qMXnTk5OVnJy8vksEQAAxLkLipvevXurd+/eXzkuPz9ftbW1qqysVE5OjqTPw6S5uVl5eXktHpOTk6OuXbuqoqJCY8eOlSTt379fBw8eVH5+viTpL3/5iz799NPoMdu3b9dPfvITbd68Wd/85jcvZCkAAMCoC4qb85Wdna1Ro0bprrvu0tKlS9XY2Kjp06fr9ttvj35S6siRIyooKNDy5cuVm5ur1NRUlZSUqLS0VD169JDf79eMGTOUn58f/aTUlwPm+PHj0de7kE9LAQAAuzyJG0l6/vnnNX36dBUUFCghIUFjx47VE088EX28sbFR+/fv1yeffBLd9/jjj0fH1tfXq7CwUE899ZRXUwQAAAZ58j03nR3fcwMAQPzp0O+5AQAA6CjEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMCWxoyfQEZxzkqS6uroOngkAADhfZ963z7yPn8tFGTcnT56UJGVmZnbwTAAAwIU6efKkUlNTz/m4z31V/hjU3Nyso0eP6rLLLpPP5+vo6XS4uro6ZWZm6tChQ/L7/R09HbM4z+2D89w+OM/tg/McyzmnkydPKiMjQwkJ576z5qK8cpOQkKB+/fp19DQ6Hb/fzx+edsB5bh+c5/bBeW4fnOcvtHbF5gxuKAYAAKYQNwAAwBTiBkpOTlZZWZmSk5M7eiqmcZ7bB+e5fXCe2wfn+eu5KG8oBgAAdnHlBgAAmELcAAAAU4gbAABgCnEDAABMIW4uAidOnND48ePl9/uVlpamkpISffzxx60ec/r0aU2bNk09e/ZU9+7dNXbsWFVXV7c49sMPP1S/fv3k8/lUW1vrwQrigxfn+e2331ZxcbEyMzPVrVs3ZWdna9GiRV4vpdNZsmSJ+vfvr5SUFOXl5Wnbtm2tjl+9erUGDhyolJQUDR48WOvXr4953Dmn+fPn6/LLL1e3bt0UDAb17rvvermEuNCW57mxsVGzZ8/W4MGDdemllyojI0MTJ07U0aNHvV5Gp9fWP8//a+rUqfL5fFq4cGEbzzrOOJg3atQoN2TIEPfGG2+4zZs3u29961uuuLi41WOmTp3qMjMzXUVFhduxY4cbPny4GzFiRItjx4wZ42688UYnyX300UcerCA+eHGe//CHP7h77rnH/etf/3L//e9/3R//+EfXrVs39+STT3q9nE5j5cqVLikpyT377LNuz5497q677nJpaWmuurq6xfGvv/6669Kli3vkkUfc3r173bx581zXrl3drl27omN++9vfutTUVLd27Vr39ttvu5tvvtldeeWV7tNPP22vZXU6bX2ea2trXTAYdKtWrXJVVVUuFAq53Nxcl5OT057L6nS8+Hk+44UXXnBDhgxxGRkZ7vHHH/d4JZ0bcWPc3r17nSS3ffv26L5//OMfzufzuSNHjrR4TG1trevatatbvXp1dN++ffucJBcKhWLGPvXUU27kyJGuoqLioo4br8/z/7r77rvdD3/4w7abfCeXm5vrpk2bFv19U1OTy8jIcOXl5S2Ov+2229zo0aNj9uXl5bmf/vSnzjnnmpubXSAQcAsWLIg+Xltb65KTk92f/vQnD1YQH9r6PLdk27ZtTpI7cOBA20w6Dnl1ng8fPuz69u3rdu/e7a644oqLPm74ZynjQqGQ0tLSNGzYsOi+YDCohIQEbd26tcVjKisr1djYqGAwGN03cOBAZWVlKRQKRfft3btXDz/8sJYvX97qf2B2MfDyPH9ZJBJRjx492m7ynVhDQ4MqKytjzlFCQoKCweA5z1EoFIoZL0mFhYXR8e+9957C4XDMmNTUVOXl5bV63i3z4jy3JBKJyOfzKS0trU3mHW+8Os/Nzc2aMGGCZs2apUGDBnkz+Thzcb8jXQTC4bD69OkTsy8xMVE9evRQOBw+5zFJSUln/QWUnp4ePaa+vl7FxcVasGCBsrKyPJl7PPHqPH/Zli1btGrVKk2ZMqVN5t3ZHT9+XE1NTUpPT4/Z39o5CofDrY4/8+uFPKd1XpznLzt9+rRmz56t4uLii/Y/gPTqPP/ud79TYmKi7rnnnrafdJwibuLUnDlz5PP5Wt2qqqo8e/25c+cqOztbd9xxh2ev0Rl09Hn+X7t379aYMWNUVlamG264oV1eE2gLjY2Nuu222+Sc09NPP93R0zGlsrJSixYt0rJly+Tz+Tp6Op1GYkdPAF/PzJkzdeedd7Y65qqrrlIgEFBNTU3M/s8++0wnTpxQIBBo8bhAIKCGhgbV1tbGXFWorq6OHrNp0ybt2rVLa9askfT5p08kqVevXnrggQf00EMPfc2VdS4dfZ7P2Lt3rwoKCjRlyhTNmzfva60lHvXq1UtdunQ565N6LZ2jMwKBQKvjz/xaXV2tyy+/PGbM0KFD23D28cOL83zGmbA5cOCANm3adNFetZG8Oc+bN29WTU1NzBX0pqYmzZw5UwsXLtT777/ftouIFx190w+8deZG1x07dkT3vfzyy+d1o+uaNWui+6qqqmJudP3Pf/7jdu3aFd2effZZJ8lt2bLlnHf9W+bVeXbOud27d7s+ffq4WbNmebeATiw3N9dNnz49+vumpibXt2/fVm/A/NGPfhSzLz8//6wbih999NHo45FIhBuK2/g8O+dcQ0ODKyoqcoMGDXI1NTXeTDzOtPV5Pn78eMzfxbt27XIZGRlu9uzZrqqqyruFdHLEzUVg1KhR7rvf/a7bunWr+/e//+0GDBgQ8xHlw4cPu6uvvtpt3bo1um/q1KkuKyvLbdq0ye3YscPl5+e7/Pz8c77GK6+8clF/Wso5b87zrl27XO/evd0dd9zhPvjgg+h2Mb1RrFy50iUnJ7tly5a5vXv3uilTpri0tDQXDoedc85NmDDBzZkzJzr+9ddfd4mJie7RRx91+/btc2VlZS1+FDwtLc397W9/c++8844bM2YMHwVv4/Pc0NDgbr75ZtevXz/31ltvxfz81tfXd8gaOwMvfp6/jE9LETcXhQ8//NAVFxe77t27O7/f7yZPnuxOnjwZffy9995zktwrr7wS3ffpp5+6u+++233jG99wl1xyifvxj3/sPvjgg3O+BnHjzXkuKytzks7arrjiinZcWcd78sknXVZWlktKSnK5ubnujTfeiD42cuRIN2nSpJjxf/7zn923v/1tl5SU5AYNGuReeumlmMebm5vdgw8+6NLT011ycrIrKChw+/fvb4+ldGpteZ7P/Ly3tP3vn4GLUVv/PH8ZceOcz7n/f7MEAACAAXxaCgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABM+X9JnGEujayxKgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(total_losses_rnn)),total_losses_rnn,color='blue',label='rnn')\n",
    "plt.plot(range(len(total_losses_gru)),total_losses_gru,color='red',label='gru')\n",
    "plt.plot(range(len(total_losses_lstm)),total_losses_lstm,color='green',label='lstm')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c4e930-0d41-4486-8214-7e94b5f569f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(corpus,prex_nums,model,time_step,device):\n",
    "    outputs = [ corpus[0],corpus[1],corpus[2] ]\n",
    "    def get_data():\n",
    "        return torch.tensor(outputs[-time_step:]).reshape(1,time_step).to(device)\n",
    "    state = model.begin_state(1,device)\n",
    "    for i in corpus[time_step:]:\n",
    "        _,state = model(get_data(),state)\n",
    "        outputs.append(i)\n",
    "    for i in range(prex_nums):\n",
    "        y,state = model(get_data(),state)\n",
    "        y = torch.argmax(y,dim=-1)\n",
    "        outputs += [y_.item() for y_ in y]\n",
    "    return outputs,state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134365ed-3485-4217-9afd-72c1464297b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rnn_predict\n",
    "with torch.no_grad():\n",
    "    str = ' I took the starting lever in one hand'\n",
    "    str = re.sub('[^A-Za-z0-9]',' ',str).lower().split()\n",
    "    corpus = voc[str]\n",
    "    predict_str,state = predict(corpus,10,net_rnn,3,device)\n",
    "    print(predict_str)\n",
    "    predict_str = ' '.join(voc(predict_str))\n",
    "    print(predict_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1976365-4689-4252-acd0-f2c3ef75a039",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 148, 1, 1010, 261, 7, 36, 95, 1, 2, 2, 19, 8, 1, 6, 1, 19, 1, 19, 75, 46, 75, 8, 6, 6, 1, 1, 1, 19, 46, 75, 75, 8, 6, 6, 1, 1, 1]\n",
      "i took the starting lever in one hand the and and time was the to the time the time traveller machine traveller was to to the the the time machine traveller traveller was to to the the the\n"
     ]
    }
   ],
   "source": [
    "# gru_predict\n",
    "with torch.no_grad():\n",
    "    str = ' I took the starting lever in one hand'\n",
    "    str = re.sub('[^A-Za-z0-9]',' ',str).lower().split()\n",
    "    corpus = voc[str]\n",
    "    predict_str,state = predict(corpus,10,net_gru,3,device)\n",
    "    print(predict_str)\n",
    "    predict_str = ' '.join(voc(predict_str))\n",
    "    print(predict_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2a6506d-e115-4342-99b6-a88337f923fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 148, 1, 1010, 261, 7, 36, 95, 1, 3, 2, 19, 1, 12, 4, 157, 12, 12, 6, 64, 5, 41, 5, 40, 3, 40, 73, 1, 19, 4, 157, 75, 12, 6, 6, 5, 41, 1]\n",
      "i took the starting lever in one hand the of and time the had i sun had had to been a be a little of little man the time i sun traveller had to to a be the\n"
     ]
    }
   ],
   "source": [
    "# lstm_predict\n",
    "with torch.no_grad():\n",
    "    str = ' I took the starting lever in one hand'\n",
    "    str = re.sub('[^A-Za-z0-9]',' ',str).lower().split()\n",
    "    corpus = voc[str]\n",
    "    predict_str,state = predict(corpus,10,net_lstm,3,device)\n",
    "    print(predict_str)\n",
    "    predict_str = ' '.join(voc(predict_str))\n",
    "    print(predict_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4003b8c4-503e-4aff-bb2c-1801611e705f",
   "metadata": {},
   "source": [
    "# torch.nn 训练模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feeeba62-750f-4227-91bd-b1296e995237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 这里很经典，如果要将rnn和linear结合起来输出就不能直接用 nn.Sequential ,因为nn.Sequential接受不到模型隐藏层的中间结果\n",
    "# GRU 期望输入 (time_step,batch_size,features) \n",
    "# MLP 期望输出 (batch_size,features)\n",
    "def error_test():\n",
    "    '''\n",
    "    \n",
    "    这个是nn.Moudule调用rnn模块的错误示例  -->  本质原因是 nn.Sequential 拿不到隐藏层中间的向量从而进行适配操作\n",
    "    \n",
    "    '''\n",
    "    gru_layyer = nn.GRU(1,256)\n",
    "    rnn_layyer = nn.RNN(1,256)\n",
    "    model_gru = nn.Sequential(\n",
    "        gru_layyer,\n",
    "        nn.Linear(256,len(voc)),\n",
    "        nn.ReLU()\n",
    "    ).to(device)\n",
    "    model_rnn = nn.Sequential(\n",
    "        rnn_layyer,\n",
    "        nn.Linear(256,len(voc)),\n",
    "        nn.ReLU()\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea98db-aaf5-4f48-882b-5768e2b967d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnn_torch(nn.Module):\n",
    "  def __init__(self, voc_size,hidden_size,select_model,num_layers=1,num_directions=1) -> None:\n",
    "    '''\n",
    "    select_model:\n",
    "      1:  rnn\n",
    "      2:  gru\n",
    "      3:  lstm\n",
    "    '''\n",
    "    super().__init__()\n",
    "    self.voc_size = voc_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.selece_model = select_model\n",
    "    self.num_layers = num_layers\n",
    "    self.num_directions = num_directions\n",
    "    self.rnn = nn.RNN(voc_size,hidden_size)   # (time_step,batch_size,voc_size)\n",
    "    self.gru = nn.GRU(voc_size,hidden_size)\n",
    "    self.lstm = nn.LSTM(voc_size,hidden_size)\n",
    "    self.dense = nn.Linear(hidden_size,voc_size)\n",
    "  \n",
    "  def forward(self,X,state):\n",
    "    '''\n",
    "    x -> (batch_size,time_step,voc_size)\n",
    "    '''\n",
    "    X = X.long()\n",
    "    X = F.one_hot(X.T,num_classes=self.voc_size).float()\n",
    "    if self.selece_model == 1:\n",
    "      X,state = self.rnn(X,state)\n",
    "    elif self.selece_model == 2:\n",
    "      X,state = self.gru(X,state)\n",
    "    elif self.selece_model == 3:\n",
    "      X,state = self.lstm(X,state)\n",
    "    X = X.reshape(-1,self.hidden_size)\n",
    "    Y = torch.relu(self.dense(X))\n",
    "    return Y,state\n",
    "  def begin_state(self,batch_size,device='cpu'):\n",
    "    if self.selece_model == 1 or self.selece_model == 2:\n",
    "      return torch.zeros((self.num_directions*self.num_layers,batch_size,self.hidden_size),device=device).float()\n",
    "    elif self.selece_model == 3:\n",
    "      return (torch.zeros((self.num_directions*self.num_layers,batch_size,self.hidden_size),device=device).float(),\n",
    "              torch.zeros((self.num_directions*self.num_layers,batch_size,self.hidden_size),device=device).float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc9131a-3da7-49a3-bfd5-736e8489a043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rnn\n",
    "torch_net = rnn_torch(voc_size=len(voc),hidden_size=256,select_model=1).to(device)\n",
    "total_losses_torch = train(torch_net,corpus,100,device,lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4c5ff96-25e6-40c6-ad3c-fd0bb2f9142b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中: 100%|██████████████████████████████████████████████████████████| 200/200 [04:48<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# gru\n",
    "torch_net_gru = rnn_torch(voc_size=len(voc),hidden_size=256,select_model=2).to(device)\n",
    "total_losses_torch_gru = train(torch_net_gru,corpus,200,device,lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abc0283a-29a5-46b0-9cd0-847aff7d209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中: 100%|██████████████████████████████████████████████████████████| 300/300 [07:54<00:00,  1.58s/it]\n"
     ]
    }
   ],
   "source": [
    "# lstm\n",
    "torch_net_lstm = rnn_torch(voc_size=len(voc),hidden_size=256,select_model=3).to(device)\n",
    "total_losses_torch_lstm = train(torch_net_lstm,corpus,300,device,lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e41633-4e4a-42b7-893b-fcb8e81810a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(range(len(total_losses_torch)),total_losses_torch,color='blue',label='torch_rnn')\n",
    "plt.plot(range(len(total_losses_torch_gru)),total_losses_torch_gru,color='red',label='torch_gru')\n",
    "plt.plot(range(len(total_losses_torch_lstm)),total_losses_torch_lstm,color='green',label='torch_lstm')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1447c11-371f-4841-8ea3-04ea29aa3ca5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 148, 1, 1010, 261, 7, 36, 95, 1, 2, 2, 19, 1, 1, 2, 19, 46, 1, 2, 2, 19, 1, 1, 2, 19, 46, 1, 2, 2, 19, 1, 1, 2, 19, 46, 1, 2, 2]\n",
      "i took the starting lever in one hand the and and time the the and time machine the and and time the the and time machine the and and time the the and time machine the and and\n"
     ]
    }
   ],
   "source": [
    "# rnn_predict\n",
    "with torch.no_grad():\n",
    "    str = ' I took the starting lever in one hand'\n",
    "    str = re.sub('[^A-Za-z0-9]',' ',str).lower().split()\n",
    "    corpus = voc[str]\n",
    "    predict_str,state = predict(corpus,10,torch_net,3,device)\n",
    "    print(predict_str)\n",
    "    predict_str = ' '.join(voc(predict_str))\n",
    "    print(predict_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8293a4c1-632d-4c5f-902e-a7fa2ac1e1ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 148, 1, 1010, 261, 7, 36, 95, 1, 1, 4, 19, 19, 3, 3, 4, 1, 1, 12, 19, 19, 3, 3, 4, 1, 1, 12, 19, 19, 3, 3, 4, 1, 1, 12, 19, 19, 3]\n",
      "i took the starting lever in one hand the the i time time of of i the the had time time of of i the the had time time of of i the the had time time of\n"
     ]
    }
   ],
   "source": [
    "# gru_predict\n",
    "with torch.no_grad():\n",
    "    str = ' I took the starting lever in one hand'\n",
    "    str = re.sub('[^A-Za-z0-9]',' ',str).lower().split()\n",
    "    corpus = voc[str]\n",
    "    predict_str,state = predict(corpus,10,torch_net_gru,3,device)\n",
    "    print(predict_str)\n",
    "    predict_str = ' '.join(voc(predict_str))\n",
    "    print(predict_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "661798b9-7495-4e42-99c1-8d0f9d233c01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 148, 1, 1010, 261, 7, 36, 95, 1, 2, 2, 40, 3, 1, 2, 1, 40, 3, 3, 3, 1, 1, 1, 40, 3, 3, 3, 1, 1, 1, 40, 3, 3, 3, 1, 1, 1, 40]\n",
      "i took the starting lever in one hand the and and little of the and the little of of of the the the little of of of the the the little of of of the the the little\n"
     ]
    }
   ],
   "source": [
    "# lstm_predict\n",
    "with torch.no_grad():\n",
    "    str = ' I took the starting lever in one hand'\n",
    "    str = re.sub('[^A-Za-z0-9]',' ',str).lower().split()\n",
    "    corpus = voc[str]\n",
    "    predict_str,state = predict(corpus,10,torch_net_lstm,3,device)\n",
    "    print(predict_str)\n",
    "    predict_str = ' '.join(voc(predict_str))\n",
    "    print(predict_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb7b08-c01b-4422-9089-d6dfcd5c92a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
